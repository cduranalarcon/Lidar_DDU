{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion of Raw lidar data to cloud and precipitation classification\n",
    "\n",
    "## Abstract\n",
    "\n",
    "This Notebook contains the post processing of the lidar data, including the spatial and temporal integration, the system calibration, background correction, SNR estimation, volume depolarization estimation, Cloud masking and hidrometeor clasification. Quick looks and some statistics are generated as well. Results are saved in netCDF format.\n",
    "\n",
    "## Import libraries\n",
    "\n",
    "Generic and own packages stored in \"lib\" are loaded to be used along the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"lib\") # adding \"lib\" path with own packages\n",
    "from Sigma_mol import sigma_mol # reads the radio sounsing and compute extinction coefficient\n",
    "from scipy.interpolate import interp1d # to interpolate modeled variables to lidar heights\n",
    "from lidar_integrating_space_time import Lidar_space_time as lidar_integ #integrates lidar raw data in height and time\n",
    "from fft_denoising import fft_denoising #maybe not used\n",
    "from klett import Klett81b #maybe not used\n",
    "import numpy as np \n",
    "import pylab #plots\n",
    "from DP_simp import DP_simp # Curve simplification\n",
    "from running_mean import running_mean # runing mean\n",
    "from time2epoch import time2epoch #maybe not used?\n",
    "#from cloud_mask_v1 import cloud_mask\n",
    "from netCDF4 import Dataset \n",
    "#from time import sleep\n",
    "from scipy import stats\n",
    "from scipy.optimize import curve_fit\n",
    "from dplots import densplot # make 2D desity plots\n",
    "from Comb_LidarMRR import Comb_LidarMRR3 as Comb_LidarMRR \n",
    "from cloud_mask_v2 import cloud_mask2\n",
    "from sm_paramTOP import sm_paramTOP\n",
    "import matplotlib\n",
    "from copy import copy\n",
    "from BG_corr import BG_corr\n",
    "import time\n",
    "from calendar import timegm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MRR and other parameters\n",
    "\n",
    "Load MRR data during the period of study. It also configures the font format and color maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#####Load MRR Data\n",
    "path_MRR = \"I:/PHD/Lidar/Inversion_V2/MRR_Data/\"\n",
    "Ze = np.loadtxt(path_MRR + \"Ze_10min.txt\")\n",
    "times_MRR = np.loadtxt(path_MRR + \"times.txt\")\n",
    "Height_MRR = np.loadtxt(path_MRR + \"Height.txt\")\n",
    "\n",
    "Zem = np.ma.masked_where(Ze == -9999, Ze)\n",
    "\n",
    "#####Load font format\n",
    "\n",
    "font = {'family' : 'serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 20}\n",
    "        \n",
    "pylab.rc('font', **font)      \n",
    "\n",
    "#####Color Parameters\n",
    "cmap = pylab.cm.jet\n",
    "bounds = np.linspace(1,3,4)\n",
    "norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)\n",
    "bounds2 = np.linspace(0,12,14)\n",
    "norm2 = matplotlib.colors.BoundaryNorm(bounds2, cmap.N)\n",
    "\n",
    "cmap2 = pylab.cm.get_cmap(cmap.name,8)\n",
    "\n",
    "##### output Temporal RESolution\n",
    "TRES = 5 #min. \n",
    "\n",
    "##### output Temporal resolution\n",
    "VRES = 4 #bins, 1bin = 3.8m # try only 1,2,3,6 bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Temporal and vertical integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "##### Dates\n",
    "#[ini, end]\n",
    "year0 = [2017, 2017]\n",
    "month0 = [9,12]\n",
    "day0 = [1,31]\n",
    "t0 = time.time()\n",
    "##### Routine\n",
    "for year in range(year0[0],year0[1]+1):\n",
    "    for month in range(month0[0],month0[1]+1):\n",
    "        for day in range(day0[0],day0[1]+1):\n",
    "    \n",
    "            path_out = \"I:/PHD/Lidar/Processing_V3/Signals/\"+str(TRES)+\"min\"+str(VRES)+\"bins/\"\n",
    "            filename1 = path_out+\"Par90/Par90_\"+str(year)+str(month).zfill(2)+str(day).zfill(2)+\"_\"+str(TRES)+\"min_\"+str(VRES)+\"bins.dat\"\n",
    "            filename2 = path_out+\"Par10/Par10_\"+str(year)+str(month).zfill(2)+str(day).zfill(2)+\"_\"+str(TRES)+\"min_\"+str(VRES)+\"bins.dat\"\n",
    "            filename3 = path_out+\"Per/Per_\"+str(year)+str(month).zfill(2)+str(day).zfill(2)+\"_\"+str(TRES)+\"min_\"+str(VRES)+\"bins.dat\"\n",
    "            \n",
    "            filename4 = path_out+\"Nprofiles/Nprofiles_\"+str(year)+str(month).zfill(2)+str(day).zfill(2)+\"_\"+str(TRES)+\"min\"+\".dat\"\n",
    "            \n",
    "            if os.path.isfile(filename1):\n",
    "                #Par90 = np.loadtxt(filename1)\n",
    "                #Par10 = np.loadtxt(filename2)\n",
    "                #Per   = np.loadtxt(filename3)\n",
    "                #r   = np.loadtxt(path_out+\"R_\"+str(TRES)+\"min_\"+str(VRES)+\"bins.dat\")\n",
    "                #npt = np.loadtxt(filename4)\n",
    "                print str(year)+str(month).zfill(2)+str(day).zfill(2)+\" Data loaded\"\n",
    "\n",
    "            else:\n",
    "                try:\n",
    "                    mat = lidar_integ(date = str(year)+\".\"+str(month).zfill(2)+\".\"+str(day).zfill(2), space = VRES, timee = TRES, \n",
    "                              path = \"G:/PC_chantal_20190131/MCS6A Data/\")\n",
    "                except:\n",
    "                    continue\n",
    "                    #print \"what\"\n",
    "                print str(year)+str(month).zfill(2)+str(day).zfill(2)+\" Data loaded\"\n",
    "                #sleep(8)\n",
    "                np.savetxt(filename1,mat[0])\n",
    "                np.savetxt(filename2,mat[1])\n",
    "                np.savetxt(filename3,mat[2])\n",
    "                #np.savetxt(path_out+\"R_\"+str(TRES)+\"min_\"+str(VRES)+\"bins.dat\",mat[3])\n",
    "                np.savetxt(filename4,mat[4])\n",
    "                #Par90 = mat[0]\n",
    "                #Par10 = mat[1]\n",
    "                #Per = mat[2]\n",
    "                #npt = mat[4]\n",
    "print \"Elapsed time = \", (time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background correction and SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for count in range(1):\n",
    "    if count > 0: print \"Next iteration\"\n",
    "    ##### Dates\n",
    "    #[ini, end]\n",
    "    year0 = [2017,2017]\n",
    "    month0 = [2,12]\n",
    "    day0 = [1,31]\n",
    "\n",
    "    ##### Routine\n",
    "    for year in range(year0[0],year0[1]+1):\n",
    "        for month in range(month0[0],month0[1]+1):\n",
    "            for day in range(day0[0],day0[1]+1):\n",
    "\n",
    "                path_in = \"I:/PHD/Lidar/Processing_V3/Signals/\"+str(TRES)+\"min\"+str(VRES)+\"bins/\"\n",
    "                filename1 = path_in+\"Par90/Par90_\"+str(year)+str(month).zfill(2)+str(day).zfill(2)+\"_\"+str(TRES)+\"min_\"+str(VRES)+\"bins.dat\"\n",
    "                filename2 = path_in+\"Par10/Par10_\"+str(year)+str(month).zfill(2)+str(day).zfill(2)+\"_\"+str(TRES)+\"min_\"+str(VRES)+\"bins.dat\"\n",
    "                filename3 = path_in+\"Per/Per_\"+str(year)+str(month).zfill(2)+str(day).zfill(2)+\"_\"+str(TRES)+\"min_\"+str(VRES)+\"bins.dat\"\n",
    "                filename4 = path_in+\"Nprofiles/Nprofiles_\"+str(year)+str(month).zfill(2)+str(day).zfill(2)+\"_\"+str(TRES)+\"min\"+\".dat\"\n",
    "\n",
    "                path_out = \"I:/PHD/Lidar/Processing_V3/Signals/\"+str(TRES)+\"min\"+str(VRES)+\"bins/\"\n",
    "                filename5 = path_in+\"Par90_bc/Par90bc_\"+str(year)+str(month).zfill(2)+str(day).zfill(2)+\"_\"+str(TRES)+\"min_\"+str(VRES)+\"bins.dat\"\n",
    "                filename6 = path_in+\"Par10_bc/Par10bc_\"+str(year)+str(month).zfill(2)+str(day).zfill(2)+\"_\"+str(TRES)+\"min_\"+str(VRES)+\"bins.dat\"\n",
    "                filename7 = path_in+\"Per_bc/Perbc_\"+str(year)+str(month).zfill(2)+str(day).zfill(2)+\"_\"+str(TRES)+\"min_\"+str(VRES)+\"bins.dat\"\n",
    "\n",
    "                filename8 = path_in+\"SNR/SNR_Par90_\"+str(year)+str(month).zfill(2)+str(day).zfill(2)+\"_\"+str(TRES)+\"min_\"+str(VRES)+\"bins.dat\"\n",
    "                filename9 = path_in+\"SNR/SNR_Par10_\"+str(year)+str(month).zfill(2)+str(day).zfill(2)+\"_\"+str(TRES)+\"min_\"+str(VRES)+\"bins.dat\"\n",
    "                filename10 = path_in+\"SNR/SNR_Per_\"+str(year)+str(month).zfill(2)+str(day).zfill(2)+\"_\"+str(TRES)+\"min_\"+str(VRES)+\"bins.dat\"\n",
    "\n",
    "                filename11 = path_in+\"Background/BG_Par90_\"+str(year)+str(month).zfill(2)+str(day).zfill(2)+\"_\"+str(TRES)+\"min_\"+str(VRES)+\"bins.dat\"\n",
    "                filename12 = path_in+\"Background/BG_Par10_\"+str(year)+str(month).zfill(2)+str(day).zfill(2)+\"_\"+str(TRES)+\"min_\"+str(VRES)+\"bins.dat\"\n",
    "                filename13 = path_in+\"Background/BG_Per_\"+str(year)+str(month).zfill(2)+str(day).zfill(2)+\"_\"+str(TRES)+\"min_\"+str(VRES)+\"bins.dat\"\n",
    "                \n",
    "                if os.path.isfile(filename13):\n",
    "                    #print str(year)+str(month).zfill(2)+str(day).zfill(2)+\" Data ready\"\n",
    "                    continue\n",
    "                \n",
    "                if os.path.isfile(filename1):\n",
    "                    Par90 = np.loadtxt(filename1)\n",
    "                    Par10 = np.loadtxt(filename2)\n",
    "                    Per   = np.loadtxt(filename3)\n",
    "                    r   = np.loadtxt(path_in+\"R_\"+str(TRES)+\"min_\"+str(VRES)+\"bins.dat\")\n",
    "                    npt = np.loadtxt(filename4)\n",
    "\n",
    "                    BG1 = np.zeros(shape = np.shape(Par90)[0])\n",
    "                    BG10 = np.zeros(shape = np.shape(Par90)[0])\n",
    "                    BG2 = np.zeros(shape = np.shape(Par90)[0])\n",
    "\n",
    "                    print str(year)+str(month).zfill(2)+str(day).zfill(2)+\" Data loaded\"\n",
    "                else:\n",
    "                    #print \"File not found\"\n",
    "                    continue\n",
    "\n",
    "                Par_bc = np.zeros(shape = np.shape(Par90))\n",
    "                Par10_bc = np.zeros(shape = np.shape(Par90))\n",
    "                Per_bc = np.zeros(shape = np.shape(Per))\n",
    "                SNR_par = np.zeros(shape = np.shape(Per))\n",
    "                SNR_par10 = np.zeros(shape = np.shape(Per))\n",
    "                SNR_per = np.zeros(shape = np.shape(Per))\n",
    "\n",
    "                for i in range(np.shape(Par90)[0]):\n",
    "                    try:\n",
    "                        BG1[i] = BG_corr(Par90[i,:],r[:],year, month, day,rcf0 = 9,pol = 'parallel')[0][1]\n",
    "                        BG10[i] = BG_corr(Par10[i,:],r[:],year, month, day,rcf0 = 9,pol = 'parallel')[0][1]\n",
    "                        BG2[i] = BG_corr(Per[i,:],r[:],year, month, day,rcf0 = 9,pol = 'perpendicular')[0][1]  \n",
    "                    except:\n",
    "                        continue\n",
    "                        \n",
    "                    if BG1[i] < 0: BG1[i] = 0\n",
    "                    if BG10[i] < 0: BG10[i] = 0\n",
    "                    if BG2[i] < 0: BG2[i] = 0\n",
    "\n",
    "                    if BG1[i] > np.nanmean(Par90[i,-50:]): BG1[i] = np.nanmean(Par90[i,-50:])\n",
    "                    if BG10[i] > np.nanmean(Par10[i,-50:]): BG10[i] = np.nanmean(Par10[i,-50:])\n",
    "                    if BG2[i] > np.nanmean(Per[i,-50:]): BG2[i] = np.nanmean(Per[i,-50:])\n",
    "\n",
    "                    Par_bc[i,:] = Par90[i,:]-BG1[i]\n",
    "                    Par10_bc[i,:] = Par10[i,:]-BG10[i]\n",
    "                    Per_bc[i,:] = Per[i,:]-BG2[i]  \n",
    "\n",
    "                    SNR_par[i,:] = (Par_bc[i,:]*(npt[i]*TRES*6)**0.5)/(Par_bc[i,:]+2*(BG1[i]))**0.5\n",
    "                    SNR_par10[i,:] = (Par10_bc[i,:]*(npt[i]*TRES*6)**0.5)/(Par10_bc[i,:]+2*(BG10[i]))**0.5\n",
    "                    SNR_per[i,:] = (Per_bc[i,:]*(npt[i]*TRES*6)**0.5)/(Per_bc[i,:]+2*(BG2[i]))**0.5\n",
    "\n",
    "                    Par_bc[i,:] = (Par_bc[i,:])*r**2\n",
    "                    Par10_bc[i,:] = (Par10_bc[i,:])*r**2\n",
    "                    Per_bc[i,:] = (Per_bc[i,:])*r**2  \n",
    "\n",
    "                np.savetxt(filename5,Par_bc)\n",
    "                np.savetxt(filename6,Par10_bc)\n",
    "                np.savetxt(filename7,Per_bc)\n",
    "\n",
    "                np.savetxt(filename8,SNR_par)\n",
    "                np.savetxt(filename9,SNR_par10)\n",
    "                np.savetxt(filename10,SNR_per)\n",
    "\n",
    "                np.savetxt(filename11,BG1)\n",
    "                np.savetxt(filename12,BG10)\n",
    "                np.savetxt(filename13,BG2)\n",
    "    #print \"waiting 15 minutes...\"\n",
    "    #time.sleep(15*60)\n",
    "    #print \"iteration = \", count\n",
    "    #month00 = month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "               \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
